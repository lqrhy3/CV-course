{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CV5_lenet_mnist.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQMyz3AQRRux",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#я не торч просто дунул\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed(0)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbR0tb0DafdB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision.datasets\n",
        "\n",
        "MNIST_train = torchvision.datasets.MNIST('./', download=True, train=True)\n",
        "MNIST_test = torchvision.datasets.MNIST('./', download=True, train=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EM3vEo-9aqFZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        },
        "outputId": "bc69b915-f373-4e9c-bab8-b0d4a674d5bf"
      },
      "source": [
        "X_train = MNIST_train.train_data\n",
        "y_train = MNIST_train.train_labels\n",
        "X_test = MNIST_test.test_data\n",
        "y_test = MNIST_test.test_labels"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:53: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:43: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:58: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:48: UserWarning: test_labels has been renamed targets\n",
            "  warnings.warn(\"test_labels has been renamed targets\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgIbCnlbUWvx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "03db4877-5b6c-462e-bd51-23d4f98230f6"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(X_train[0, :, :], cmap='Greys')\n",
        "plt.show()\n",
        "print(y_train[0])\n"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhedBhRoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y65Crq1Ua9yi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "4c703d23-71cb-4a35-f44b-329712227039"
      },
      "source": [
        "len(X_train), len(y_train)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 60000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vQuLpYzbDq1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "ddc6a75b-4d31-4041-82f2-62369c9f986f"
      },
      "source": [
        "#добавим размерность, отвечающую кол-ву каналов\n",
        "X_train = X_train.unsqueeze(1).float()\n",
        "X_test = X_test.unsqueeze(1).float()\n",
        "\n",
        "X_train.shape, X_test.shape"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([60000, 1, 28, 28]), torch.Size([10000, 1, 28, 28]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQvtsZQ2lb3Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = X_test.to(device)\n",
        "y_test = y_test.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOKe5eafbOHe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "class LeNet5(torch.nn.Module):\n",
        "  def __init__(self, n_epochs=5000, lr=0.001, batch_size=100):\n",
        "    self.n_epochs = n_epochs\n",
        "    self.lr = lr\n",
        "    self.batch_size = batch_size\n",
        "    \n",
        "    super(LeNet5, self).__init__()\n",
        "    \n",
        "    self.conv1 = torch.nn.Conv2d(\n",
        "                  in_channels=1, out_channels=6, kernel_size=5, padding=2) \n",
        "    self.act1 = torch.nn.Tanh()\n",
        "    self.pool1 = torch.nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "    \n",
        "    self.conv2 = torch.nn.Conv2d(\n",
        "                  in_channels=6, out_channels=16, kernel_size=5, padding=0) \n",
        "    self.act2 = torch.nn.Tanh()\n",
        "    self.pool2 = torch.nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "    \n",
        "    self.fc1 = torch.nn.Linear(5 * 5 * 16, 120)\n",
        "    self.act3 = torch.nn.Tanh()\n",
        "    \n",
        "    self.fc2 = torch.nn.Linear(120, 84)\n",
        "    self.act4 = torch.nn.Tanh()\n",
        "    \n",
        "    self.fc3 = torch.nn.Linear(84, 10)\n",
        "    \n",
        "    self.sm = torch.nn.Softmax(dim=1)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.act1(x)\n",
        "    x = self.pool1(x)\n",
        "      \n",
        "    x = self.conv2(x)\n",
        "    x = self.act2(x)\n",
        "    x = self.pool2(x)\n",
        "      \n",
        "    x = x.view(x.size(0), x.size(1) * x.size(2) * x.size(3))\n",
        "      \n",
        "    x = self.fc1(x)\n",
        "    x = self.act3(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.act4(x)\n",
        "    x = self.fc3(x)\n",
        "      \n",
        "    return x\n",
        "    \n",
        "  def train(self, x, y):\n",
        "    loss = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(self.parameters(), self.lr)\n",
        "    \n",
        "    for _ in range(self.n_epochs):\n",
        "      shuffled_indexes = np.random.permutation(x.shape[0])\n",
        "      \n",
        "      for start_index in range(0, x.shape[0], self.batch_size):\n",
        "        x_batch = x[shuffled_indexes[start_index:start_index + self.batch_size]].to(device)\n",
        "        y_batch = y[shuffled_indexes[start_index:start_index + self.batch_size]].to(device)\n",
        "       \n",
        "        optimizer.zero_grad()\n",
        "        y_out = self.forward(x_batch)\n",
        "        loss_value = loss(y_out, y_batch)\n",
        "        loss_value.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "      print(accuracy_score(self.predict(X_test), y_test))\n",
        "      \n",
        "    return self\n",
        "    \n",
        "  def predict(self, x):\n",
        "    return self.forward(x).argmax(dim=1)\n",
        "    \n",
        "  def predict_proba(x):\n",
        "    return self.sm(self.forward(x))\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMTK7Rh7SDVp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.is_available()\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P343twJJStiH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lenet5 = LeNet5(n_epochs=20)\n",
        "lenet5 = lenet5.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQQM1DgzTCbf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "191a5d79-558d-4091-b6dc-87ef9869c9a6"
      },
      "source": [
        "lenet5.train(X_train, y_train)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9749\n",
            "0.9831\n",
            "0.9835\n",
            "0.9872\n",
            "0.9882\n",
            "0.9875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-102-fc32db2c9b52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlenet5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-99-bcee562641e4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0my_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mloss_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6Bm-jxQTHlM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}