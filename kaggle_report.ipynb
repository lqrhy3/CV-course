{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle соревенование \"Dirty vs Cleaned\"\n",
    " https://www.kaggle.com/c/platesv2/overview\n",
    "<br><br>Необходимо решить задачу классификации тарелок на две категории \"чистые\" и \"грязные\".\n",
    "Одна из особенностей задачи --- размер тренировчного набора данных. Всего 40 картинок, по 20 картинок на каждый класс. Тестовая выборка состоит из 744 картинок.\n",
    "<br>\n",
    "<br>\n",
    "Примеры изображений из тренировочной выборки:\n",
    "<br>\n",
    "<img style=\"float: left;\" src=\"0014.jpg\">\n",
    "<img  src=\"0013.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Подключение к диску, импорт библиотек и фиксирование random_seed для частичной воспроизводимости."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gt9LyU4cGL93"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 120
    },
    "colab_type": "code",
    "id": "zxmsmEDIGQL2",
    "outputId": "e3363c21-917e-434e-b27f-b2c2b7ebc5e7"
   },
   "outputs": [],
   "source": [
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "cUeBq6DCK1Im",
    "outputId": "e85bb6b0-68c7-4c00-9bc4-dc4d5131c42b"
   },
   "outputs": [],
   "source": [
    "%cd 'gdrive/My Drive/Colab Notebooks/CV_Course/Kaggle/plates/plates/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "aP9NWDaRFYM6",
    "outputId": "f2a57d41-82bb-4d1e-cf53-e05d9cd0e914"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hzqt68-lMeH5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "random.seed(8)\n",
    "np.random.seed(8)\n",
    "torch.manual_seed(8)\n",
    "torch.cuda.manual_seed(8)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wlkb0VyFFYNM"
   },
   "outputs": [],
   "source": [
    "import shutil \n",
    "\n",
    "train_dir = 'train'\n",
    "val_dir = 'val'\n",
    "\n",
    "class_names = ['cleaned', 'dirty']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных и аугментации\n",
    "<br>Функция для цветовой инверсии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LykAUxdpy035"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from PIL import ImageOps\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "def my_inverse_transformation(img, p=0.5):\n",
    "    if not F._is_pil_image(img):\n",
    "        raise TypeError('img should be PIL Image. Got {}'.format(type(img)))\n",
    "    if random.random() > p:\n",
    "        return ImageOps.invert(img)\n",
    "    else:\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Класс трансформации для сегментации тарелки и отделения ее от фона с помощью преобразования Хофа.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dKdFtzA5dVIE"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "from torchvision.transforms.functional import _is_pil_image\n",
    "from torchvision import transforms, models\n",
    "\n",
    "\n",
    "class Segmentate:\n",
    "    center_crop = transforms.CenterCrop(224)\n",
    "    initThresh = 105\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if not _is_pil_image(img):\n",
    "            raise TypeError('Img should be PIL Image. Got {}'.format(type(img)))\n",
    "\n",
    "        cimg = img.copy()\n",
    "        img = np.array(img)\n",
    "\n",
    "        # Convert to gray-scale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        p1 = self.initThresh\n",
    "        p2 = self.initThresh * 0.4\n",
    "\n",
    "        # Detect circles using HoughCircles transform\n",
    "        circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, 1, 500, param1=p1, param2=p2, minRadius=10,\n",
    "                                   maxRadius=170)\n",
    "\n",
    "        t = 400\n",
    "        if circles is None:\n",
    "            return self.center_crop(cimg)\n",
    "\n",
    "        c = np.uint16(np.around(circles))[0, 0]\n",
    "\n",
    "        # Draw the outer circle\n",
    "        cv2.circle(img, (c[0], c[1]), c[2] + t // 2 - 15, (0, 0, 0), t)\n",
    "\n",
    "        thr = -10\n",
    "        # Centering ad cropping\n",
    "        try:\n",
    "            img = img[c[1] - c[2] - thr:c[1] + c[2] + thr, c[0] - c[2] - thr:c[0] + c[2] + thr]\n",
    "            pil_img = Image.fromarray(img)\n",
    "        except ValueError:\n",
    "            return cimg\n",
    "\n",
    "        return pil_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Класс трансформации для изменения контраста изображения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vIEmKaeAuUBn"
   },
   "outputs": [],
   "source": [
    "class ChangeContrast:\n",
    "    def __init__(self, level):\n",
    "        self.level = level\n",
    "        \n",
    "    def __call__(self, img):\n",
    "        self.factor_ = (259 * (self.level + 255)) / (255 * (259 - self.level))\n",
    "        def contrast(c):\n",
    "            return 128 + self.factor_ * (c - 128)\n",
    "        return img.point(contrast)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(contrast_level={})'.format(self.level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Создание datasets.ImageFolder и DataLoader для загрузки картинок, создание батчей и автоматического применения трансформаций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5JZ0sB10FYNS"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "import PIL\n",
    "\n",
    "shift_const = [0.485, 0.456, 0.406]\n",
    "scale_const = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Pad(50, padding_mode='edge'),\n",
    "    transforms.RandomRotation((0, 360), expand=True),\n",
    "    transforms.CenterCrop(224),    \n",
    "    # ChangeContrast(65),\n",
    "    # Segmentate(),\n",
    "    # transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    # transforms.ColorJitter(0.5, 0.6, 0.4, 0.25),\n",
    "    # transforms.Lambda(lambda x: my_inverse_transformation(x, 0.3)),\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Lambda(lambda x: x[np.random.permutation(3), :, :]),\n",
    "    transforms.Normalize(shift_const, scale_const)\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.CenterCrop(224),\n",
    "    # ChangeContrast(65),\n",
    "    # Segmentate(),\n",
    "    # transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(shift_const, scale_const)\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder(train_dir, train_transforms)\n",
    "val_dataset = torchvision.datasets.ImageFolder(val_dir, val_transforms)\n",
    "\n",
    "batch_size = 20\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, num_workers=batch_size)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=True, num_workers=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "iF5Ar1deFYNZ",
    "outputId": "9fd88c60-6f90-4b0e-81df-fa3a4d939bd9"
   },
   "outputs": [],
   "source": [
    "print(len(train_loader), len(train_dataset))\n",
    "print(len(val_loader), len(val_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Функции для отображения данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mNQN9ny_FYNm"
   },
   "outputs": [],
   "source": [
    "def show_input(input_tensor, title=''):\n",
    "    image = input_tensor.permute(1, 2, 0).numpy() * scale_const + shift_const\n",
    "    plt.imshow(image.clip(0, 1))\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    plt.pause(0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Визуализируем данные после применения аугментаций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Kz5IU1a3FYNs",
    "outputId": "fcab0d3e-ed81-4fef-ad1a-3b7dad9c00d2"
   },
   "outputs": [],
   "source": [
    "X_batch, y_batch = next(iter(train_loader))\n",
    "\n",
    "for x_item, y_item in zip(X_batch, y_batch):\n",
    "    show_input(x_item, title=class_names[y_item])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примеры изображений:\n",
    "<br>\n",
    "<img style=\"float: left;\" src=\"Безымянный3.jpg\">\n",
    "<img  src=\"Безымянный4.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание моделей\n",
    "<br>Модуль pretrainedmodels для предобученных моделей для дальнейшего transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 405
    },
    "colab_type": "code",
    "id": "a0GsdfC5mAq4",
    "outputId": "da1b1717-35da-4ebd-896f-a185fc2722a5"
   },
   "outputs": [],
   "source": [
    "!pip install pretrainedmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Функции инциализации претреннированных на ImageNet моделей. Последний слой отрезается и заменяется на подходящий полносвязный слой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UiJ4LdqzfNE9"
   },
   "outputs": [],
   "source": [
    "def make_pnasnet():\n",
    "    import pretrainedmodels\n",
    "    model = pretrainedmodels.pnasnet5large(num_classes=1000)\n",
    "    model.last_linear = torch.nn.Linear(model.last_linear.in_features, 2)\n",
    "\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    return model\n",
    "\n",
    "\n",
    "def make_xception():\n",
    "    import pretrainedmodels\n",
    "    model = pretrainedmodels.xception()\n",
    "    model.last_linear = torch.nn.Linear(model.last_linear.in_features, 2)\n",
    "\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    return model\n",
    "\n",
    "\n",
    "def make_resnext():\n",
    "    import pretrainedmodels\n",
    "    model = pretrainedmodels.se_resnext50_32x4d()\n",
    "    model.last_linear = torch.nn.Linear(model.last_linear.in_features, 2)\n",
    "\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    return model\n",
    "\n",
    "def make_inception_resnet_v2():\n",
    "    import pretrainedmodels\n",
    "    model = pretrainedmodels.inceptionresnetv2()\n",
    "\n",
    "    model.last_linear = torch.nn.Linear(model.last_linear.in_features, 2)\n",
    "    \n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    return model\n",
    "\n",
    "def make_vgg():\n",
    "    model = models.vgg19_bn(pretrained=True)\n",
    "    child_counter = 0\n",
    "    for child in model.features.children():\n",
    "        if child_counter < 48:\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = False\n",
    "        child_counter += 1\n",
    "        \n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    return model\n",
    "\n",
    "def make_resnet():\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    model.fc = torch.nn.Linear(model.fc.in_features,2)\n",
    "\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение моделей\n",
    "<br>Класс для поиска наилучшей комбинации гиперпараметров перебором по сетке параметров. Процедура особенно необходма из-за маленького количества обучающих примеров, которые образуют сильно неустойчивое, \"рваное\" пространство, в котором изменяются веса. Поэтому каждую тренировку надежнее проводить таким способом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xm64GqIZhTJf"
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "from itertools import product\n",
    "\n",
    "class GridSearch():\n",
    "    def __init__(self, loss, optimizer=torch.optim.SGD, optimizer_params={}, scheduler=torch.optim.lr_scheduler.StepLR, scheduler_params={}):\n",
    "        \"\"\"\n",
    "        [object]_params : dict\n",
    "            Словарь, значения которого - списки значений именованных параметров объекта [object] \n",
    "            ----\n",
    "            Пример:\n",
    "                scheduler_params={'step_size': [7], 'gamma': [0.1, 0.01, 0.001]}\n",
    "        \"\"\"\n",
    "        self.loss = loss\n",
    "        self.optimizer = optimizer\n",
    "        self.optimizer_params = optimizer_params\n",
    "        self.scheduler = scheduler\n",
    "        self.scheduler_params = scheduler_params\n",
    "        self.best_model = ...\n",
    "        self.best_acc = 0\n",
    "        \n",
    "    def tune(self, create_model_func):\n",
    "        \n",
    "        self.param_grid_ = list(product(*{**self.optimizer_params, **self.scheduler_params}.values()))\n",
    "        self.param_grid_score_ = {}\n",
    "        \n",
    "        self.param_grid_len_ = len(self.param_grid_)\n",
    "        for (i, param_set) in enumerate(self.param_grid_):\n",
    "            print('Parameters set {}/{}'.format(i, self.param_grid_len_), end='\\n')\n",
    "            print(param_set)\n",
    "\n",
    "            self.model_ = create_model_func()\n",
    "            \n",
    "            if self.optimizer == torch.optim.SGD:\n",
    "                self.optimizer_ = self.optimizer(self.model_.parameters(), *param_set[:len(self.optimizer_params)])\n",
    "            elif self.optimizer == torch.optim.Adam:\n",
    "                self.optimizer_ = self.optimizer(self.model_.parameters(), *param_set[:len(self.optimizer_params)])\n",
    "            else:\n",
    "                raise RuntimeError('unknown type of optimizer')\n",
    "                \n",
    "            self.scheduler_ = self.scheduler(self.optimizer_, *param_set[len(self.optimizer_params):])\n",
    "\n",
    "            _, best_model, score = train_model(self.model_, self.loss, self.optimizer_, self.scheduler_, n_epochs=26)\n",
    "            if score > self.best_acc:\n",
    "                self.best_model = copy.deepcopy(best_model)\n",
    "                self.best_acc = score\n",
    "            else:\n",
    "                del best_model\n",
    "#             self.current_score_ = sum(score[-3:]) / 3\n",
    "            \n",
    "#             self.param_grid_score_[str(param_set)[1:-1]] = self.current_score_\n",
    "#         self.best_score_ = max(self.param_grid_score_.values())\n",
    "#         self.best_params_ = max(self.param_grid_score_, key=lambda key: self.param_grid_score_[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Функция тренировки модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S8j4IF1sRsWZ"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "def train_model(model, loss, optimizer, scheduler, n_epochs):\n",
    "    best_acc = 0\n",
    "    validation_accuracy = []\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        print('Epoch {}:'.format(epoch))\n",
    "        \n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                dataloader = train_loader\n",
    "                model.train()\n",
    "            else:\n",
    "                dataloader = val_loader\n",
    "                model.eval()\n",
    "                \n",
    "            batch_loss = 0.\n",
    "            batch_acc = 0.\n",
    "            \n",
    "            for inputs, labels in dataloader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    preds = model(inputs)\n",
    "                    loss_val = loss(preds, labels)\n",
    "                    preds_class = preds.argmax(dim=1)\n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        loss_val.backward()\n",
    "                        optimizer.step()\n",
    "                        scheduler.step()\n",
    "                        \n",
    "                batch_loss += loss_val.item()\n",
    "                batch_acc += (preds_class == labels.data).float().mean().item()\n",
    "                \n",
    "            epoch_loss = batch_loss / len(dataloader)\n",
    "            epoch_acc = batch_acc / len(dataloader)\n",
    "            \n",
    "            if phase == 'val':\n",
    "                validation_accuracy.append(epoch_acc)\n",
    "                if epoch_acc > best_acc:\n",
    "                    best_model = copy.deepcopy(model)\n",
    "                    best_acc = epoch_acc\n",
    "        \n",
    "            print('{} Loss: {:.3f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "    return model, best_model, best_acc    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y3lyuoYt8OCd"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Функция потерь - бинарная кросс энтропия, так как задача бинарной классификации\n",
    "<br> Оптимизатор - стохастический градиентый спуск, так как поддается наиболее тонкой настройке\n",
    "<br> Планировщик - косинусный планировщик с отжигом, так как поверхность функкции потерь неустойчивая и необходимо побывать как можно в большем количестве локальных минимумов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cpdp2Tu8F9um"
   },
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer_params={'lr': [0.01, 0.1],\n",
    "                  'momentum': [0.9, 0],\n",
    "                  'dampening': [0.01],\n",
    "                  'weight_decay': [0.1, 0.0001, 1],\n",
    "                  'nesterov': [False]\n",
    "                 }\n",
    "scheduler_params = {'T_max': [5, 15]}\n",
    "\n",
    "model_cv = GridSearch(loss, optimizer=torch.optim.SGD, optimizer_params=optimizer_params,\n",
    "                     scheduler=torch.optim.lr_scheduler.CosineAnnealingLR, scheduler_params=scheduler_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Тренируем модель на разных наборах гиперпараметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "zTXJCWB43bLO",
    "outputId": "8e5e40f6-fbf6-4981-d112-2320a3529be8"
   },
   "outputs": [],
   "source": [
    "model_cv.tune(make_inception_resnet_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "2Wy6bm9nS33s",
    "outputId": "18423631-bd13-447a-a4ad-596b759584b8"
   },
   "outputs": [],
   "source": [
    "model_cv.best_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Дообучаем лучшую на модель на лучшем наборе гиперпараметров в надежде получить более высокий результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "colab_type": "code",
    "id": "m99ZpRmnFYN4",
    "outputId": "cd0f3995-6d51-4552-f99f-a086be7a1140"
   },
   "outputs": [],
   "source": [
    "best_model = copy.deepcopy(model_cv.best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hr5VQL0CYIks"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(best_model.parameters(), lr=0.09, momentum=0.4, dampening=0.1, weight_decay=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ajvleeC2FYOA",
    "outputId": "d49b9457-ab1c-4a9a-8497-c68335d9f593"
   },
   "outputs": [],
   "source": [
    "_, final_model, val_acc = train_model(best_model, loss, optimizer, scheduler, n_epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предсказание\n",
    "<br>Лучшая модель получена, можно делать предсказание\n",
    "<br><br>Загружаем тестовый набор данных, немного изменяя библитечный класс datasets.ImageFolder для сохранения пути до картинки, который впоследствии послужит для создания индексов в датафрейме."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "NzRdqF7GFYOH",
    "outputId": "c1fea75c-d055-4dfb-f05b-780c20d29737"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "test_dir = 'test'\n",
    "data_root = 'gdrive/My Drive/Colab Notebooks/CV_Course/Kaggle/plates/plates'\n",
    "shutil.copytree(os.path.join(data_root, 'test'), os.path.join('gdrive/My Drive/Colab Notebooks/CV_Course/Kaggle/plates/plates/test', 'unknown'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "15L5JKGYFYOO"
   },
   "outputs": [],
   "source": [
    "class ImageFolderWithPaths(torchvision.datasets.ImageFolder):\n",
    "    def __getitem__(self, index):\n",
    "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
    "        path = self.imgs[index][0]\n",
    "        tuple_with_path = (original_tuple + (path, ))\n",
    "        return tuple_with_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YTBiMJMxFYOU"
   },
   "outputs": [],
   "source": [
    "test_dataset = ImageFolderWithPaths('test', val_transforms)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=744,\n",
    "                                         shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Функция предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SSSwk35LFYOa"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "def evaluate(model, loader): \n",
    "    model.eval()\n",
    "\n",
    "    test_predictions = []\n",
    "    test_img_paths = []\n",
    "    for inputs, _, paths in loader:\n",
    "        inputs = inputs.to(device)\n",
    "        with torch.set_grad_enabled(False):\n",
    "            preds = model(inputs)\n",
    "        test_predictions.append(torch.nn.functional.softmax(preds, dim=1)[:, 1].data.cpu().numpy())\n",
    "        test_img_paths.extend(paths)\n",
    "\n",
    "    test_predictions = np.concatenate(test_predictions)\n",
    "    return test_predictions, test_img_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yVaY_xBFI890"
   },
   "outputs": [],
   "source": [
    "test_predictions, test_img_paths = evaluate(the_best_model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Посмотрим на полученнные предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tOBHfR4kFYOr"
   },
   "outputs": [],
   "source": [
    "inputs, labels, paths = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "L6qH-uZBqiea",
    "outputId": "6d2c1cf8-7fa1-4edd-f7e8-05d3c2f0d3d1"
   },
   "outputs": [],
   "source": [
    "for img, pred in zip(inputs, test_predictions):\n",
    "     show_input(img, title=pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Пример предсказаний:\n",
    "<br>\n",
    "<img style=\"float: left;\" src=\"Безымянный2.jpg\">\n",
    "<img  src=\"Безымянный.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Формируем файл с предсказаниями для сабмита."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cWkiIvx1FYOx"
   },
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame.from_dict({'id': test_img_paths,\n",
    "                                        'label': test_predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gIwwTL5NFYO3"
   },
   "outputs": [],
   "source": [
    "submission_df['label'] = submission_df['label'].map(lambda pred: 'dirty'\n",
    "                                                   if pred > 0.5 else 'cleaned')\n",
    "submission_df['id'] = submission_df['id'].str.replace('test/unknown/', '')\n",
    "submission_df['id'] = submission_df['id'].str.replace('.jpg', '')\n",
    "submission_df.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "colab_type": "code",
    "id": "nBLTA8AFFYPA",
    "outputId": "4c21abc7-37aa-4933-d479-a54992a9e1bc"
   },
   "outputs": [],
   "source": [
    "submission_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"123.jpg\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SCiIKYB-FYPN"
   },
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9o5RXbnRFYPY"
   },
   "outputs": [],
   "source": [
    "!rm -rf train val test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Сабмитим и получаем... 0.955"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Submitted_9529.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
